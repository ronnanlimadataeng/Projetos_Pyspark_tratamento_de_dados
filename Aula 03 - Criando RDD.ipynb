{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com RDD e executando transformações\n",
    "\n",
    "1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\")\n",
    "2. Com uso de RDD faça as seguintes operações\n",
    "a) Contar a quantidade de linhas\n",
    "b) Visualizar a primeira linha\n",
    "c) Visualizar todas as linhas\n",
    "d) Contar a quantidade de palavras\n",
    "e) Converter todas as palavras em minúsculas\n",
    "f) Remover as palavras de tamanho menor que 2\n",
    "g) Atribuir o valor de 1 para cada palavra\n",
    "h) Contar as palavras com o mesmo nome\n",
    "i) Visualizar em ordem alfabética\n",
    "j) Visualizar em ordem decrescente a quantidade de palavras\n",
    "k) Remover as palavras, com a quantidade de palavras > 1\n",
    "l) Salvar o RDD no diretorio do HDFS /user/<seu-nome>/logs_count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out\r\n"
     ]
    }
   ],
   "source": [
    "#lendo diretorio spark antes\n",
    "!ls /opt/spark/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080\r\n",
      "========================================\r\n",
      "20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: \r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: \r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\r\n",
      "20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\r\n",
      "20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077\r\n",
      "20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1\r\n",
      "20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms\r\n",
      "20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown\r\n",
      "20/03/18 20:31:10 INFO server.Server: Started @1504ms\r\n",
      "20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}\r\n",
      "20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE\r\n"
     ]
    }
   ],
   "source": [
    "#lendo arquivo spark\n",
    "#1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\")\n",
    "!cat /opt/spark/logs/spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = sc.textFile(\"file:///opt/spark/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a) Contar a quantidade de linhas\n",
    "log.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) Visualizar a primeira linha\n",
    "log.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080',\n",
       " '========================================',\n",
       " '20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\",\n",
       " '20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077',\n",
       " '20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1',\n",
       " '20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms',\n",
       " '20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown',\n",
       " '20/03/18 20:31:10 INFO server.Server: Started @1504ms',\n",
       " '20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\",\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c) Visualizar todas as linhas , cuidado super perigoso em produção\n",
    "log.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d) Contar a quantidade de palavras\n",
    "#1 -  separar as palavras da linha(flatMap)\n",
    "palavras = log.flatMap(lambda linha: linha.split(\" \"))\n",
    "#2 - contando a quantidade\n",
    "palavras.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e) Converter todas as palavras em minúsculas\n",
    "minuscula = palavras.map(lambda palavra: palavra.lower())\n",
    "minuscula.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f) Remover as palavras de tamanho menor que 2\n",
    "minuscula_maior2 = minuscula.filter(lambda palavra: len(palavra) >2)\n",
    "minuscula_maior2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spark', 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#g) Atribuir o valor de 1 para cada palavra\n",
    "palavra_1 = minuscula_maior2.map(lambda palavra: (palavra,1))\n",
    "palavra_1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#h) Contar as palavras com o mesmo nome\n",
    "palavras_reduce = palavra_1.reduceByKey(lambda chave1, chave2, : chave1 + chave2)\n",
    "palavras_reduce.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i) Visualizar em ordem alfabética\n",
    "palavras_reduce = palavra_1.reduceByKey(lambda chave1, chave2, : chave1 + chave2)\n",
    "palavras_reduce.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'masterui'\", 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('--host', 1),\n",
       " ('--port', 1),\n",
       " ('--webui-port', 1),\n",
       " ('-cp', 1),\n",
       " ('-xmx1g', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('2.4.1', 1),\n",
       " ('20/03/18', 28),\n",
       " ('20:31:09', 4),\n",
       " ('20:31:10', 24),\n",
       " ('7077', 1),\n",
       " ('7077.', 1),\n",
       " ('8080', 1),\n",
       " ('8080.', 1),\n",
       " ('========================================', 1),\n",
       " ('@1454ms', 1),\n",
       " ('@1504ms', 1),\n",
       " ('acls', 5),\n",
       " ('alive', 1),\n",
       " ('and', 1),\n",
       " ('authentication', 1),\n",
       " ('been', 1),\n",
       " ('bound', 1),\n",
       " ('build', 1),\n",
       " ('changing', 4),\n",
       " ('command:', 1),\n",
       " ('daemon', 1),\n",
       " ('disabled;', 2),\n",
       " ('elected', 1),\n",
       " ('for', 3),\n",
       " ('git', 1),\n",
       " ('groups', 4),\n",
       " ('handler', 3),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('hash:', 1),\n",
       " ('have', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('hup', 1),\n",
       " ('info', 28),\n",
       " ('initialized', 1),\n",
       " ('int', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('leader!', 1),\n",
       " ('localhost', 1),\n",
       " ('logging', 1),\n",
       " ('master', 1),\n",
       " ('master.master:', 4),\n",
       " ('masterwebui', 1),\n",
       " ('modify', 4),\n",
       " ('name:', 1),\n",
       " ('new', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('permissions:', 4),\n",
       " ('port', 2),\n",
       " ('process', 1),\n",
       " ('registered', 3),\n",
       " ('root', 2),\n",
       " ('running', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('server.server:', 2),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " ('service', 2),\n",
       " ('set()', 1),\n",
       " ('set();', 1),\n",
       " ('set(root);', 2),\n",
       " ('signal', 3),\n",
       " ('spark', 3),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('started', 15),\n",
       " ('starting', 1),\n",
       " ('state:', 1),\n",
       " ('successfully', 2),\n",
       " ('term', 1),\n",
       " ('timestamp:', 1),\n",
       " ('to:', 4),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('unknown', 1),\n",
       " ('unknown,', 1),\n",
       " ('users', 2),\n",
       " ('util.log:', 1),\n",
       " ('util.signalutils:', 3),\n",
       " ('util.utils:', 2),\n",
       " ('version', 1),\n",
       " ('view', 4),\n",
       " ('with', 5)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#j) Visualizar em ordem decrescente a quantidade de palavras\n",
    "palavras_ordem = palavras_reduce.sortBy(lambda palavra: palavra[0],True)\n",
    "palavras_ordem.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('7077', 1),\n",
       " ('--webui-port', 1),\n",
       " ('8080', 1),\n",
       " ('daemon', 1),\n",
       " ('process', 1),\n",
       " ('term', 1),\n",
       " ('int', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('set();', 1),\n",
       " ('set()', 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('starting', 1),\n",
       " ('master', 1),\n",
       " ('version', 1),\n",
       " ('2.4.1', 1),\n",
       " ('util.log:', 1),\n",
       " ('logging', 1),\n",
       " ('@1454ms', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('timestamp:', 1),\n",
       " ('git', 1),\n",
       " ('hash:', 1),\n",
       " ('unknown', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('masterwebui', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('have', 1),\n",
       " ('leader!', 1),\n",
       " ('new', 1),\n",
       " ('state:', 1),\n",
       " ('command:', 1),\n",
       " ('-cp', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('-xmx1g', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('--host', 1),\n",
       " ('localhost', 1),\n",
       " ('--port', 1),\n",
       " ('========================================', 1),\n",
       " ('name:', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('hup', 1),\n",
       " ('authentication', 1),\n",
       " ('7077.', 1),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('running', 1),\n",
       " ('initialized', 1),\n",
       " ('build', 1),\n",
       " ('unknown,', 1),\n",
       " ('@1504ms', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " (\"'masterui'\", 1),\n",
       " ('8080.', 1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('bound', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('and', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('been', 1),\n",
       " ('elected', 1),\n",
       " ('alive', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k) Remover as palavras, com a quantidade de palavras > 1\n",
    "palavras_ordem_qtd = palavras_reduce.sortBy(lambda palavra: palavra[1],False)\n",
    "palavras_ordem_qtd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_ordem_filtro = palavras_ordem_qtd.filter(lambda palavra: palavra[1] > 1)\n",
    "palavras_ordem_filtro.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l) Salvar o RDD no diretorio do HDFS /user/<seu-nome>/logs_count_word\n",
    "palavras_ordem_filtro.saveAsTextFile(\"/user/ronnan/logs_count_four\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-04-09 14:43 /user/ronnan/logs_count_four/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        517 2022-04-09 14:43 /user/ronnan/logs_count_four/part-00000\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-04-09 14:43 /user/ronnan/logs_count_four/part-00001\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ronnan/logs_count_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RDD com partições continuação\n",
    "\n",
    "#1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\") com 10 partições\n",
    "#2. Contar a quantidade de cada palavras do RDD em 5 partições\n",
    "#3. Salvar o RDD no diretório do HDFS /user/<seu-nome>/logs_count_word_5\n",
    "#4. Refazer a questão 2, com todas as funções na mesma linha de um RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out\r\n"
     ]
    }
   ],
   "source": [
    "#lendo diretorio spark antes\n",
    "!ls /opt/spark/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\") com 10 partições\n",
    "log_particoes = sc.textFile(\"file:///opt/spark/logs\",10)\n",
    "log_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_particoes = log_particoes.flatMap(lambda linha: linha.split(\" \"),5) \n",
    "palavras_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_minuscula_particoes = palavras_particoes.map(lambda palavra: palavra.lower(), 8)\n",
    "palavras_minuscula_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_count_particoes = palavras_minuscula_particoes.map(lambda palavra: (palavra,1), 7)\n",
    "palavras_count_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Contar a quantidade de cada palavras do RDD em 5 partições\n",
    "palavras_reduce_particoes = palavras_count_particoes.reduceByKey (lambda x,y:x+y, 5) \n",
    "palavras_reduce_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Salvar o RDD no diretório do HDFS /user/<seu-nome>/logs_count_word_5\n",
    "palavras_reduce_particoes.saveAsTextFile(\"/user/ronnan/logs_count_five2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Refazer a questão 2, com todas as funções na mesma linha de um RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/ronnan/logs_count_five1\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -R /user/ronnan/logs_count_five1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-04-09 14:50 /user/ronnan/logs_count_five2/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        575 2022-04-09 14:50 /user/ronnan/logs_count_five2/part-00000\r\n",
      "-rw-r--r--   2 root supergroup        208 2022-04-09 14:50 /user/ronnan/logs_count_five2/part-00001\r\n",
      "-rw-r--r--   2 root supergroup        444 2022-04-09 14:50 /user/ronnan/logs_count_five2/part-00002\r\n",
      "-rw-r--r--   2 root supergroup        772 2022-04-09 14:50 /user/ronnan/logs_count_five2/part-00003\r\n",
      "-rw-r--r--   2 root supergroup        785 2022-04-09 14:50 /user/ronnan/logs_count_five2/part-00004\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ronnan/logs_count_five2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_particoes_linha = log_particoes.flatMap (lambda linha: linha.split(\" \")).map(lambda palavra: palavra.lower()).map(lambda palavra: (palavra,1)).reduceByKey (lambda x,y:x+y, 5)\n",
    "palavras_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--port', 1),\n",
       " ('20:31:09', 4),\n",
       " ('daemon', 1),\n",
       " ('process', 1),\n",
       " ('registered', 3),\n",
       " ('signal', 3),\n",
       " ('20:31:10', 24),\n",
       " ('to:', 4),\n",
       " ('groups', 4),\n",
       " ('', 4),\n",
       " ('authentication', 1),\n",
       " ('users', 2),\n",
       " ('permissions:', 4),\n",
       " ('on', 2),\n",
       " ('starting', 1),\n",
       " ('at', 2),\n",
       " ('2.4.1', 1),\n",
       " ('util.log:', 1),\n",
       " ('timestamp:', 1),\n",
       " ('@1504ms', 1),\n",
       " (\"'masterui'\", 1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('to', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('have', 1),\n",
       " ('elected', 1),\n",
       " ('alive', 1),\n",
       " ('command:', 1),\n",
       " ('-cp', 1),\n",
       " ('info', 28),\n",
       " ('int', 1),\n",
       " ('acls', 5),\n",
       " ('modify', 4),\n",
       " ('util.utils:', 2),\n",
       " ('7077.', 1),\n",
       " ('master', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('8080.', 1),\n",
       " ('bound', 1),\n",
       " ('masterwebui', 1),\n",
       " ('and', 1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('8080', 1),\n",
       " ('20/03/18', 28),\n",
       " ('name:', 1),\n",
       " ('util.signalutils:', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('running', 1),\n",
       " ('version', 1),\n",
       " ('logging', 1),\n",
       " ('@1454ms', 1),\n",
       " ('server.server:', 2),\n",
       " ('unknown', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('been', 1),\n",
       " ('leader!', 1),\n",
       " ('new', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('localhost', 1),\n",
       " ('--webui-port', 1),\n",
       " ('started', 15),\n",
       " ('changing', 4),\n",
       " ('securitymanager:', 1),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('set();', 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('initialized', 1),\n",
       " ('git', 1),\n",
       " ('hash:', 1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('spark', 3),\n",
       " ('-xmx1g', 1),\n",
       " ('--host', 1),\n",
       " ('7077', 1),\n",
       " ('========================================', 1),\n",
       " ('master.master:', 4),\n",
       " ('with', 5),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('term', 1),\n",
       " ('hup', 1),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('view', 4),\n",
       " ('root', 2),\n",
       " ('ui', 1),\n",
       " ('set()', 1),\n",
       " ('port', 2),\n",
       " ('build', 1),\n",
       " ('unknown,', 1),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('i', 1),\n",
       " ('state:', 1)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_particoes_linha.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
